# -*- coding: utf-8 -*-
"""Breast_Cancer_Classification (21016) .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MIBD13KVAV4XjvK7ZxeGqleZFFn7ZHJg

Â© Ritwik Chandra Pandey


2nd MSc (Maths) - Specialisation in CS

##IMPORTING LIBRARIES
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.model_selection import cross_val_score, train_test_split, KFold, StratifiedShuffleSplit, GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from imblearn.over_sampling import SMOTE
from sklearn.metrics import confusion_matrix,roc_auc_score, recall_score,precision_score,accuracy_score

"""##IMPORTING THE DATASET"""

from sklearn.datasets import load_breast_cancer
df = pd.DataFrame(load_breast_cancer()['data'], columns=load_breast_cancer()['feature_names'])
df['y'] = load_breast_cancer()['target']

"""## BASIC INFORMATION ABOUT THE DATASET

### Number of Null values in each column of df
"""

pd.set_option('display.max_rows', None)
df.isnull().sum()

df.info()

#Describing the label to be predicted in train.scv
df['y'].describe()

#Getting the frequency of each value in df['y']
M = df['y'].value_counts()[0]
B = df['y'].value_counts()[1]
Total = B+M
print('Benign values in the dataset : ' + str(B))
print('Malignant values in the dataset : ' + str(M))
print('Percent of Benign values in the dataset: ' + str((B/Total)*100) + " %")
print('Percent of Malignant values in the dataset: ' + str((M/Total)*100) + " %")

"""Malignant is represented using 0 and Benign is represented using 1 in the dataset."""

df.head()

"""## DATA PREPROCESSING

### Feature Scaling
"""

target = df['y']
df_dropped = df.drop('y', axis = 1)
sc = StandardScaler()
df_dropped = sc.fit_transform(df_dropped)

"""## SPLITTING THE DATASET"""

X, y = df_dropped, target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=118)

"""## HANDLING DATA IMBALANCE USING SMOTE"""

print("Before OverSampling, counts of label '1' - Benign: {}".format(sum(y_train==1)))
print("Before OverSampling, counts of label '0' - Malignant: {} \n".format(sum(y_train==0)))
print('Before OverSampling, the shape of train_X: {}'.format(X_train.shape))
print('Before OverSampling, the shape of train_y: {} \n'.format(y_train.shape))

sm = SMOTE(random_state=2)
X_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())

print('After OverSampling, the shape of train_X_res: {}'.format(X_train_res.shape))
print('After OverSampling, the shape of train_y_res: {} \n'.format(y_train_res.shape))

print("After OverSampling, counts of label '1'  - Benign: {}".format(sum(y_train_res==1)))
print("After OverSampling, counts of label '0' - Malignant: {}".format(sum(y_train_res==0)))

"""## CLASSIFICATION USING DECISION TREE

#### Without OverSampling
"""

clf = DecisionTreeClassifier()

#Tuning the hyperparameters of the Decision tree model
dt_tuned_parameters = {'criterion':['gini','entropy'],'max_depth':[10,20,50,100],'min_samples_leaf':[10, 20, 50]}

#Fitting the model
cv_grid = GridSearchCV(clf, param_grid = dt_tuned_parameters, scoring = 'roc_auc', verbose = 5) 
cv_grid.fit(X_train, y_train)

cv_grid.cv_results_

best_parameters = cv_grid.best_estimator_.get_params()
best_parameters

"""#### With OverSampling"""

clf = DecisionTreeClassifier()

#Tuning the hyperparameters of the Decision tree model
dt_tuned_parameters = {'criterion':['gini','entropy'],'max_depth':[10,20,50,100],'min_samples_leaf':[10, 20, 50]}

#Fitting the model
cv_grid_oversampled = GridSearchCV(clf, param_grid = dt_tuned_parameters, scoring = 'roc_auc', verbose = 5) 
cv_grid_oversampled.fit(X_train_res, y_train_res)

cv_grid_oversampled.cv_results_

best_parameters = cv_grid_oversampled.best_estimator_.get_params()
best_parameters

pred_test_dt_tuned = cv_grid_oversampled.predict(X_test)
print("recall score on validation data: " + str(recall_score(y_test, pred_test_dt_tuned)))     
print("precision score on validation data: " + str(precision_score(y_test, pred_test_dt_tuned)))  
print("roc auc score on validation data: " + str(roc_auc_score(y_test, pred_test_dt_tuned)))  
print("accuracy score on validation data: " + str(accuracy_score(y_test, pred_test_dt_tuned)))  
print("confusion matrix on validation data: \n" + str(confusion_matrix(y_test, pred_test_dt_tuned)))
print('\n\n\n')
pred_test_dt_tuned_oversampled = cv_grid.predict(X_test)
print("recall score on validation data (with oversampling): " + str(recall_score(y_test, pred_test_dt_tuned_oversampled)))     
print("precision score on validation data (with oversampling): " + str(precision_score(y_test, pred_test_dt_tuned_oversampled)))  
print("roc auc score on validation data (with oversampling): " + str(roc_auc_score(y_test, pred_test_dt_tuned_oversampled)))  
print("accuracy score on validation data (with oversampling): " + str(accuracy_score(y_test, pred_test_dt_tuned_oversampled)))  
print("confusion matrix on validation data (with oversampling): \n" + str(confusion_matrix(y_test, pred_test_dt_tuned_oversampled)))

"""##### It is noted that handling data imbalance gives slightly better results.

## CLASSIFICATION USING K-NEAREST NEIGHBOR

#### Without OverSampling

#### Model Fitting for K = 3
"""

model3 = KNeighborsClassifier(n_neighbors=3)
model3.fit(X_train,y_train)

"""#### Model Fitting for K = 5"""

model5 = KNeighborsClassifier(n_neighbors=5)
model5.fit(X_train,y_train)

"""#### Model Fitting for K = 7"""

model7 = KNeighborsClassifier(n_neighbors=7)
model7.fit(X_train,y_train)

"""####With OverSampling
#### Model Fitting for K = 3
"""

model3_os = KNeighborsClassifier(n_neighbors=3)
model3_os.fit(X_train_res,y_train_res)

"""#### Model Fitting for K = 5"""

model5_os = KNeighborsClassifier(n_neighbors=5)
model5_os.fit(X_train_res,y_train_res)

"""#### Model Fitting for K = 7"""

model7_os = KNeighborsClassifier(n_neighbors=7)
model7_os.fit(X_train_res,y_train_res)

"""#####Comparing all results of KNN models"""

#Predict Output
pred_test_knn_3 = model3.predict(X_test)
print("recall score on validation data k = 3: " + str(recall_score(y_test, pred_test_knn_3)))     
print("precision score on validation data k = 3: " + str(precision_score(y_test, pred_test_knn_3)))  
print("roc auc score on validation data k = 3: " + str(roc_auc_score(y_test, pred_test_knn_3)))    
print("accuracy score on validation data k = 3: " + str(accuracy_score(y_test, pred_test_knn_3)))
print("confusion matrix on validation data k = 3: \n" + str(confusion_matrix(y_test, pred_test_knn_3)))
#Predict Output
pred_test_knn_3_os = model3_os.predict(X_test)
print("recall score on validation data k = 3 (with oversampling): " + str(recall_score(y_test, pred_test_knn_3_os)))     
print("precision score on validation data k = 3 (with oversampling): " + str(precision_score(y_test, pred_test_knn_3_os)))  
print("roc auc score on validation data k = 3 (with oversampling): " + str(roc_auc_score(y_test, pred_test_knn_3_os)))    
print("accuracy score on validation data k = 3 (with oversampling): " + str(accuracy_score(y_test, pred_test_knn_3_os)))
print("confusion matrix on validation data k = 3 (with oversampling): \n" + str(confusion_matrix(y_test, pred_test_knn_3_os)))
print('\n\n\n')

#Predict Output
pred_test_knn_5 = model5.predict(X_test)
print("recall score on validation data k = 5: " + str(recall_score(y_test, pred_test_knn_5)))     
print("precision score on validation data k = 5: " + str(precision_score(y_test, pred_test_knn_5)))  
print("roc auc score on validation data k = 5: " + str(roc_auc_score(y_test, pred_test_knn_5)))    
print("accuracy score on validation data k = 5: " + str(accuracy_score(y_test, pred_test_knn_5)))
print("confusion matrix on validation data k = 5: \n" + str(confusion_matrix(y_test, pred_test_knn_5)))
#Predict Output
pred_test_knn_5_os = model5_os.predict(X_test)
print("recall score on validation data k = 5 (with oversampling): " + str(recall_score(y_test, pred_test_knn_5_os)))     
print("precision score on validation data k = 5 (with oversampling): " + str(precision_score(y_test, pred_test_knn_5_os)))  
print("roc auc score on validation data k = 5 (with oversampling): " + str(roc_auc_score(y_test, pred_test_knn_5_os)))    
print("accuracy score on validation data k = 5 (with oversampling): " + str(accuracy_score(y_test, pred_test_knn_5_os)))
print("confusion matrix on validation data k = 5 (with oversampling): \n" + str(confusion_matrix(y_test, pred_test_knn_5_os)))
print('\n\n\n')

#Predict Output
pred_test_knn_7 = model7.predict(X_test)
print("recall score on validation data k = 7: " + str(recall_score(y_test, pred_test_knn_7)))     
print("precision score on validation data k = 7: " + str(precision_score(y_test, pred_test_knn_7)))  
print("roc auc score on validation data k = 7: " + str(roc_auc_score(y_test, pred_test_knn_7))) 
print("accuracy score on validation data k = 7: " + str(accuracy_score(y_test, pred_test_knn_7)))   
print("confusion matrix on validation data k = 7: \n" + str(confusion_matrix(y_test, pred_test_knn_7)))
#Predict Output
pred_test_knn_7_os = model7_os.predict(X_test)
print("recall score on validation data k = 7 (with oversampling): " + str(recall_score(y_test, pred_test_knn_7_os)))     
print("precision score on validation data k = 7 (with oversampling): " + str(precision_score(y_test, pred_test_knn_7_os)))  
print("roc auc score on validation data k = 7 (with oversampling): " + str(roc_auc_score(y_test, pred_test_knn_7_os)))    
print("accuracy score on validation data k = 7 (with oversampling): " + str(accuracy_score(y_test, pred_test_knn_7_os)))
print("confusion matrix on validation data k = 7 (with oversampling): \n" + str(confusion_matrix(y_test, pred_test_knn_7_os)))

"""It is noted that oversampling here does not help much.



## CLASSIFICATION USING GRADIENT BOOSTING MACHINE (GBM)

#### Without OverSampling
"""

#Learning rate = 0.1
gradient_booster_1 = GradientBoostingClassifier(learning_rate=0.1)
gradient_booster_1.fit(X_train,y_train)
pred_test_gb_1 = gradient_booster_1.predict(X_test)

#Learning rate = 0.2
gradient_booster_2 = GradientBoostingClassifier(learning_rate=0.2)
gradient_booster_2.fit(X_train,y_train)
pred_test_gb_2 = gradient_booster_2.predict(X_test)

#Learning rate = 0.3
gradient_booster_3 = GradientBoostingClassifier(learning_rate=0.3)
gradient_booster_3.fit(X_train,y_train)
pred_test_gb_3 = gradient_booster_3.predict(X_test)

"""#### With OverSampling"""

#Learning rate = 0.1
gradient_booster_os_1 = GradientBoostingClassifier(learning_rate=0.1)
gradient_booster_os_1.fit(X_train_res,y_train_res)
pred_test_gb_os_1 = gradient_booster_os_1.predict(X_test)

#Learning rate = 0.2
gradient_booster_os_2 = GradientBoostingClassifier(learning_rate=0.2)
gradient_booster_os_2.fit(X_train_res,y_train_res)
pred_test_gb_os_2 = gradient_booster_os_2.predict(X_test)

#Learning rate = 0.3
gradient_booster_os_3= GradientBoostingClassifier(learning_rate=0.3)
gradient_booster_os_3.fit(X_train_res,y_train_res)
pred_test_gb_os_3 = gradient_booster_os_3.predict(X_test)

print("recall score on validation data (learning rate = 0.1): " + str(recall_score(y_test, pred_test_gb_1)))     
print("precision score on validation data (learning rate = 0.1): " + str(precision_score(y_test, pred_test_gb_1)))  
print("roc auc score on validation data (learning rate = 0.1): " + str(roc_auc_score(y_test, pred_test_gb_1)))  
print("accuracy score on validation data (learning rate = 0.1): " + str(accuracy_score(y_test, pred_test_gb_1)))  
print("confusion matrix on validation data (learning rate = 0.1): \n" + str(confusion_matrix(y_test, pred_test_gb_1)))

print("recall score on validation data (learning rate = 0.1 -> with oversampling): " + str(recall_score(y_test, pred_test_gb_os_1)))     
print("precision score on validation data (learning rate = 0.1 -> with oversampling): " + str(precision_score(y_test, pred_test_gb_os_1)))  
print("roc auc score on validation data (learning rate = 0.1 -> with oversampling): " + str(roc_auc_score(y_test, pred_test_gb_os_1)))  
print("accuracy score on validation data (learning rate = 0.1 -> with oversampling): " + str(accuracy_score(y_test, pred_test_gb_os_1)))  
print("confusion matrix on validation data (learning rate = 0.1 -> with oversampling): \n" + str(confusion_matrix(y_test, pred_test_gb_os_1)))

print('\n\n\n')

print("recall score on validation data (learning rate = 0.2): " + str(recall_score(y_test, pred_test_gb_2)))     
print("precision score on validation data (learning rate = 0.2): " + str(precision_score(y_test, pred_test_gb_2)))  
print("roc auc score on validation data (learning rate = 0.2): " + str(roc_auc_score(y_test, pred_test_gb_2)))  
print("accuracy score on validation data (learning rate = 0.2): " + str(accuracy_score(y_test, pred_test_gb_2)))  
print("confusion matrix on validation data (learning rate = 0.2): \n" + str(confusion_matrix(y_test, pred_test_gb_2)))

print("recall score on validation data (learning rate = 0.2 -> with oversampling): " + str(recall_score(y_test, pred_test_gb_os_2)))     
print("precision score on validation data (learning rate = 0.2 -> with oversampling): " + str(precision_score(y_test, pred_test_gb_os_2)))  
print("roc auc score on validation data (learning rate = 0.2 -> with oversampling): " + str(roc_auc_score(y_test, pred_test_gb_os_2)))  
print("accuracy score on validation data (learning rate = 0.2 -> with oversampling): " + str(accuracy_score(y_test, pred_test_gb_os_2)))  
print("confusion matrix on validation data (learning rate = 0.2 -> with oversampling): \n" + str(confusion_matrix(y_test, pred_test_gb_os_2)))

print('\n\n\n')

print("recall score on validation data (learning rate = 0.3): " + str(recall_score(y_test, pred_test_gb_3)))     
print("precision score on validation data (learning rate = 0.3): " + str(precision_score(y_test, pred_test_gb_3)))  
print("roc auc score on validation data (learning rate = 0.3): " + str(roc_auc_score(y_test, pred_test_gb_3)))  
print("accuracy score on validation data (learning rate = 0.3): " + str(accuracy_score(y_test, pred_test_gb_3)))  
print("confusion matrix on validation data (learning rate = 0.3): \n" + str(confusion_matrix(y_test, pred_test_gb_3)))

print("recall score on validation data (learning rate = 0.3 -> with oversampling): " + str(recall_score(y_test, pred_test_gb_os_3)))     
print("precision score on validation data (learning rate = 0.3 -> with oversampling): " + str(precision_score(y_test, pred_test_gb_os_3)))  
print("roc auc score on validation data (learning rate = 0.3 -> with oversampling): " + str(roc_auc_score(y_test, pred_test_gb_os_3)))  
print("accuracy score on validation data (learning rate = 0.3 -> with oversampling): " + str(accuracy_score(y_test, pred_test_gb_os_3)))  
print("confusion matrix on validation data (learning rate = 0.3 -> with oversampling): \n" + str(confusion_matrix(y_test, pred_test_gb_os_3)))

"""It is noted that oversampling here does not help much.

## CLASSIFICATION USING RANDOM FOREST

####Without OverSampling
"""

estimator = RandomForestClassifier(random_state=0, warm_start = True)
estimator.fit(X_train,y_train)
pred_test_rf = estimator.predict(X_test)

"""####With OverSampling"""

estimator_os = RandomForestClassifier(random_state=0, warm_start = True)
estimator_os.fit(X_train_res,y_train_res)
pred_test_rf_os = estimator_os.predict(X_test)

print("recall score on validation data: " + str(recall_score(y_test, pred_test_rf)))     
print("precision score on validation data: " + str(precision_score(y_test, pred_test_rf)))  
print("roc auc score on validation data: " + str(roc_auc_score(y_test, pred_test_rf)))  
print("accuracy score on validation data: " + str(accuracy_score(y_test, pred_test_rf)))  
print("confusion matrix on validation data: \n" + str(confusion_matrix(y_test, pred_test_rf)))
print('\n\n\n')
print("recall score on validation data (with oversampling): " + str(recall_score(y_test, pred_test_rf_os)))     
print("precision score on validation data (with oversampling): " + str(precision_score(y_test, pred_test_rf_os)))  
print("roc auc score on validation data (with oversampling): " + str(roc_auc_score(y_test, pred_test_rf_os)))  
print("accuracy score on validation data (with oversampling): " + str(accuracy_score(y_test, pred_test_rf_os)))  
print("confusion matrix on validation data (with oversampling): \n" + str(confusion_matrix(y_test, pred_test_rf_os)))

"""It is noted that oversampling improves the predictions to a marginal extent.

### COMPARING ALL MODELS
"""

df_recall = pd.DataFrame(data = [recall_score(y_test, pred_test_dt_tuned),recall_score(y_test, pred_test_knn_3)\
                                 , recall_score(y_test, pred_test_knn_5),\
                             recall_score(y_test, pred_test_knn_7),\
                             recall_score(y_test, pred_test_gb_1),recall_score(y_test, pred_test_gb_2)\
                             ,recall_score(y_test, pred_test_gb_3),\
                             recall_score(y_test, pred_test_rf)], \
                     index = ['Decision Tree', 'KNN (K = 3)'\
                              ,'KNN (K = 5)','KNN (K = 7)','GB (LR = 0.1)','GB (LR = 0.2)','GB (LR = 0.3)',\
                              'Random Forest'],
                     columns = ['Recall Score'])
df_roc = pd.DataFrame(data = [roc_auc_score(y_test, pred_test_dt_tuned),roc_auc_score(y_test, pred_test_knn_3)\
                                 , roc_auc_score(y_test, pred_test_knn_5),\
                             roc_auc_score(y_test, pred_test_knn_7),\
                             roc_auc_score(y_test, pred_test_gb_1),roc_auc_score(y_test, pred_test_gb_2)\
                             ,roc_auc_score(y_test, pred_test_gb_3),\
                             roc_auc_score(y_test, pred_test_rf)], \
                     index = ['Decision Tree', 'KNN (K = 3)'\
                              ,'KNN (K = 5)','KNN (K = 7)','GB (LR = 0.1)','GB (LR = 0.2)','GB (LR = 0.3)',\
                              'Random Forest'],
                     columns = ['ROC AUC Score'])
df_precision = pd.DataFrame(data = [precision_score(y_test, pred_test_dt_tuned),precision_score(y_test, pred_test_knn_3)\
                                 , precision_score(y_test, pred_test_knn_5),\
                             precision_score(y_test, pred_test_knn_7),\
                             precision_score(y_test, pred_test_gb_1),precision_score(y_test, pred_test_gb_2)\
                             ,precision_score(y_test, pred_test_gb_3),\
                             precision_score(y_test, pred_test_rf)], \
                     index = ['Decision Tree', 'KNN (K = 3)'\
                              ,'KNN (K = 5)','KNN (K = 7)','GB (LR = 0.1)','GB (LR = 0.2)','GB (LR = 0.3)',\
                              'Random Forest'],
                     columns = ['Precision Score'])
df_accuracy =  pd.DataFrame(data = [accuracy_score(y_test, pred_test_dt_tuned),accuracy_score(y_test, pred_test_knn_3)\
                                 , accuracy_score(y_test, pred_test_knn_5),\
                             accuracy_score(y_test, pred_test_knn_7),\
                             accuracy_score(y_test, pred_test_gb_1),accuracy_score(y_test, pred_test_gb_2)\
                             ,accuracy_score(y_test, pred_test_gb_3),\
                             accuracy_score(y_test, pred_test_rf)], \
                     index = ['Decision Tree', 'KNN (K = 3)'\
                              ,'KNN (K = 5)','KNN (K = 7)','GB (LR = 0.1)','GB (LR = 0.2)','GB (LR = 0.3)',\
                              'Random Forest'],
                     columns = ['Accuracy Score'])

df_recall_os =  pd.DataFrame(data = [accuracy_score(y_test, pred_test_dt_tuned_oversampled),recall_score(y_test, pred_test_knn_3_os)\
                                 , recall_score(y_test, pred_test_knn_5_os),\
                             accuracy_score(y_test, pred_test_knn_7_os),\
                             recall_score(y_test, pred_test_gb_os_1),recall_score(y_test, pred_test_gb_os_3)\
                             ,recall_score(y_test, pred_test_gb_os_3),\
                             recall_score(y_test, pred_test_rf_os)], \
                     index = ['Decision Tree (OverSampled)', 'KNN (K = 3) (OverSampled)'\
                              ,'KNN (K = 5) (OverSampled)','KNN (K = 7) (OverSampled)','GB (LR = 0.1) (OverSampled)',\
                              'GB (LR = 0.2) (OverSampled)','GB (LR = 0.3) (OverSampled)',\
                              'Random Forest (OverSampled)'],
                     columns = ['Recall Score'])

df_roc_os = pd.DataFrame(data = [roc_auc_score(y_test, pred_test_dt_tuned_oversampled),roc_auc_score(y_test, pred_test_knn_3_os)\
                                 , roc_auc_score(y_test, pred_test_knn_5_os),\
                             roc_auc_score(y_test, pred_test_knn_7_os),\
                             roc_auc_score(y_test, pred_test_gb_os_1),roc_auc_score(y_test, pred_test_gb_os_2)\
                             ,roc_auc_score(y_test, pred_test_gb_os_3),\
                             roc_auc_score(y_test, pred_test_rf_os)], \
                     index = ['Decision Tree (OverSampled)', 'KNN (K = 3) (OverSampled)'\
                              ,'KNN (K = 5) (OverSampled)','KNN (K = 7) (OverSampled)','GB (LR = 0.1) (OverSampled)',\
                              'GB (LR = 0.2) (OverSampled)','GB (LR = 0.3) (OverSampled)',\
                              'Random Forest (OverSampled)'],
                     columns = ['ROC AUC Score'])

df_precision_os = pd.DataFrame(data = [precision_score(y_test, pred_test_dt_tuned_oversampled),precision_score(y_test, pred_test_knn_3_os)\
                                 , precision_score(y_test, pred_test_knn_5_os),\
                             precision_score(y_test, pred_test_knn_7_os),\
                             precision_score(y_test, pred_test_gb_os_1),precision_score(y_test, pred_test_gb_os_2)\
                             ,precision_score(y_test, pred_test_gb_os_3),\
                             precision_score(y_test, pred_test_rf_os)], \
                    index = ['Decision Tree (OverSampled)', 'KNN (K = 3) (OverSampled)'\
                              ,'KNN (K = 5) (OverSampled)','KNN (K = 7) (OverSampled)','GB (LR = 0.1) (OverSampled)',\
                              'GB (LR = 0.2) (OverSampled)','GB (LR = 0.3) (OverSampled)',\
                              'Random Forest (OverSampled)'],
                     columns = ['Precision Score'])

df_accuracy_os =  pd.DataFrame(data = [accuracy_score(y_test, pred_test_dt_tuned_oversampled),accuracy_score(y_test, pred_test_knn_3_os)\
                                 , accuracy_score(y_test, pred_test_knn_5_os),\
                             accuracy_score(y_test, pred_test_knn_7_os),\
                             accuracy_score(y_test, pred_test_gb_os_1),accuracy_score(y_test, pred_test_gb_os_2)\
                             ,accuracy_score(y_test, pred_test_gb_os_3),\
                             accuracy_score(y_test, pred_test_rf_os)], \
                     index = ['Decision Tree (OverSampled)', 'KNN (K = 3) (OverSampled)'\
                              ,'KNN (K = 5) (OverSampled)','KNN (K = 7) (OverSampled)','GB (LR = 0.1) (OverSampled)',\
                              'GB (LR = 0.2) (OverSampled)','GB (LR = 0.3) (OverSampled)',\
                              'Random Forest (OverSampled)'],
                     columns = ['Accuracy Score'])

df_all = pd.concat([df_recall, df_roc, df_precision, df_accuracy], axis = 1)
display(df_all)
df_all_os = pd.concat([df_recall_os, df_roc_os, df_precision_os, df_accuracy_os], axis = 1)
display(df_all_os)

